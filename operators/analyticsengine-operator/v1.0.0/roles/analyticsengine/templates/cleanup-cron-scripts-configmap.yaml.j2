apiVersion: v1
kind: ConfigMap
metadata:
  name: "{{ name }}-cleanup-scripts"
  labels:
    function: "{{ name }}-cleanup-scripts"
{% if cpdLabels  %} 
    {{ cpdLabels | to_nice_yaml| indent(4) }}
{% endif %}
data:
  cleanup-spark-jobs.py: |-
    #!/usr/bin/python
    '''
    Script to cleanup spark jobs
    '''
    
    # ---------------------------------------------  IMPORTS --------------------------------------------- #
    
    import json, datetime, time
    import argparse
    import requests
    import sys
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    # ---------------------------------------------  FUNCTIONS -------------------------------------------- #
    def purge_active_jobs(job_service_url,instance_id,hb_endpoint,purge_time):
        print("Purge request for instance {}".format(instance_id))
        j_response = requests.get("{}/{}/jobs/meta/list?state=ACTIVE".format(job_service_url, instance_id), headers=headers, verify=False, timeout=120)
        if j_response.status_code == 200:
            jobs = j_response.json()
            for job in jobs:
                job_id = job["job_id"]
                print("Purge request for instance {} job_id {}".format(instance_id,job_id))
                url = "{}/{}/v2/jobs/{}".format(hb_endpoint, instance_id, job_id)
                if "jobState" not in job:
                    print("job_state not found, cluster state {}".format(job["state"]))
                    job_state = ""
                    try:
                      print("Try to get Job State")
                      getjob_response = requests.get(url, headers=headers, verify=False, timeout=5)
                      if getjob_response.status_code != 200:
                          print("\n\n\nCould not found jobState, making get call on job : {}, cluster_state : {}, HTTP code : {}\n\n\n".format(job_id,state,getjob_response.status_code))
                      else:
                          print("\n\n\nCould not found jobState, failed get on job : {}, cluster_state : {}, HTTP code : {}\n\n\n".format(job_id,state,getjob_response.status_code))
                      return 0
                    except (requests.Timeout, requests.ConnectionError, KeyError) as e:
                      print("Timeout occurred - move forward")
                else:
                    job_state = job["jobState"]
                    print("Found Job State {}".format(job_state))
    
                if (job_state == "FAILED") or (job_state == "FINISHED"):
                    if "start_time" in job:
                        job_time = job["start_time"]
                    elif "finish_time" in job:
                        job_time = job["finish_time"]
                    elif "fail_time" in job:
                        job_time = job["fail_time"]
                    else:
                        getjob_response = requests.get(url, headers=headers, verify=False)
                        if getjob_response.status_code != 200:
                            print("\n\n\nCould not found  any time, making get call on job : {}, cluster_state : {}, HTTP code : {}\n\n\n".format(job_id,state,getjob_response.status_code))
                        else:
                            print("\n\n\nCould not found any time, failed get on job : {}, cluster_state : {}, HTTP code : {}\n\n\n".format(job_id,state,getjob_response.status_code))
                        return 0
                else:
                    try:
                      print("Try to get Job Updated State")
                      getjob_response = requests.get(url, headers=headers, verify=False, timeout=5)
                      if getjob_response.status_code != 200:
                          print("\n\n\nCould not found finish_time, making get call on job : {}, HTTP code : {}\n\n\n".format(job_id,getjob_response.status_code))
                      else:
                         print("\n\n\nCould not found finish_time, failed get on job : {}, HTTP code : {}\n\n\n".format(job_id,getjob_response.status_code))
                      return 0
                    except (requests.Timeout, requests.ConnectionError, KeyError) as e:
                      print("Timeout occurred - move forward")
    
                if (job_state == "FAILED") or (job_state == "FINISHED"):
                  print("job_time : {}".format(job_time))
                  date_time_str = job_time.split('.')[0]
                  date_time_obj = datetime.datetime.strptime(date_time_str, '%A %d %B %Y %H:%M:%S')
                  job_time_sec = time.mktime(date_time_obj.timetuple())
    
                  current_time = time.time()
                  diff_in_min = (current_time - time.mktime(date_time_obj.timetuple()))/60
                  if diff_in_min >= purge_time:
                      url = "{}/{}/v2/jobs/{}".format(hb_endpoint, instance_id, job_id)
                      try:
                        dj_response = requests.delete(url, headers=headers, verify=False,timeout=40)
                        if dj_response.status_code != 204:
                            print("\n\n\nFailed to delete job_id : {}, job_state : {}, time diff : {}, HTTP code : {}\n\n\n".format(job_id,job_state,diff_in_min,dj_response.status_code))
                        else:
                            print("\n\n\nDeleted job_id : {}, job_state : {}, time diff : {}, HTTP code : {}\n\n\n".format(job_id,job_state,diff_in_min,dj_response.status_code))
                      except (requests.Timeout, requests.ConnectionError, KeyError) as e:
                        print("Timeout occurred in deleting JOB {} - move forward".format(job_id))
        else:
            print("Failed to get jobs in state : ACTIVE. HTTP Code : {}".format(j_response.status_code))
    
    def purge_failed_or_delete_failed_jobs(job_service_url,instance_id,hb_endpoint,purge_time):
        j_response = requests.get("{}/{}/jobs/meta/list?state=FAILED&state=DELETE_FAILED".format(job_service_url, instance_id), headers=headers, verify=False, timeout=120)
        if j_response.status_code == 200:
            jobs = j_response.json()
    
            for job in jobs:
                job_id = job["job_id"]
                state = job["state"]
                url = "{}/{}/v2/jobs/{}".format(hb_endpoint, instance_id, job_id)
                try:
                  dj_response = requests.delete(url, headers=headers, verify=False,timeout=40)
                  if dj_response.status_code != 204:
                      print("\n\n\nFailed to delete job_id : {}, cluster_state : {}, HTTP code : {}\n\n\n".format(job_id,state,dj_response.status_code))
                  else:
                      print("\n\n\nDeleted job_id : {}, cluster_state : {},  HTTP code : {}\n\n\n".format(job_id,state,dj_response.status_code))
                except (requests.Timeout, requests.ConnectionError, KeyError) as e:
                  print("Timeout occurred in deleting JOB {} - move forward".format(job_id))
        else:
            print("Failed to get jobs in state : FAILED,DELETE_FAILED. HTTP Code : {}".format(j_response.status_code))
    
    
    # ---------------------------------------------  PARSE ARGS ------------------------------------------- #
    parser = argparse.ArgumentParser()
    parser.add_argument("instance_manager_url", help="Instance manager url to get instance details")
    parser.add_argument("hb_endpoint", help="Hummingbird endpoint url to delete jobs")
    parser.add_argument("job_service_url", help="Job service url to get metadata of jobs")
    parser.add_argument("purge_time_file", help="purge time for FINISHED / FAILED jobs")
    args = parser.parse_args()
    
    
    # ---------------------------------------------  BUILD JSON  ------------------------------------------- #
    instance_manager_url = args.instance_manager_url
    hb_endpoint = args.hb_endpoint
    job_service_url = args.job_service_url
    
    purge_time_file = args.purge_time_file
    
    print("Start HB Jobs cleanup")
    
    with open(purge_time_file) as json_file:
        data = json.load(json_file)
        purge_time = data["spark"]["idleTimeBeforeShutdown"]
        purge_time = purge_time
        print("setting purge time : {}mins".format(purge_time))
    
    
    headers = {'Content-Type':'application/json','Accept':'application/json'}
    response = requests.get("{}/list".format(instance_manager_url), headers=headers, verify=False, timeout=120)
    if response.status_code == 200:
        instances = response.json()
    
        for instance in instances:
            instance_id = instance["_id"]
            print("Get the instance details for instance {}".format(instance_id))
            if "api_key" not in instance:
                api_key = None
            else:
                api_key = instance["api_key"]
    
            headers = {'Accept':'application/json','X-Api-Key':api_key}
    
            if purge_time == -1:
                purge_failed_or_delete_failed_jobs(job_service_url,instance_id,hb_endpoint,purge_time)
            else:
                purge_active_jobs(job_service_url,instance_id,hb_endpoint,purge_time)
                purge_failed_or_delete_failed_jobs(job_service_url,instance_id,hb_endpoint,purge_time)
        exit(0)
    else:
        print("Failed to get instances, got responseCode {}".format(response))
        exit(2)
  purge_idle_failed_kernel.py: |-
    #!/usr/bin/python
    '''
    Script to cleanup spark jobs
    '''

    import json, time
    from datetime import datetime
    import argparse
    import requests
    import sys
    import urllib3
    import subprocess

    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    def purge_active_kernels(kernel_service_url,instance_id,hb_endpoint,purge_time):
        print("Purge request for instance {}".format(instance_id))
        k_response = requests.get("{}/{}/meta/api/kernels?state=Active".format(kernel_service_url, instance_id), headers=headers, verify=False, timeout=120)
        if k_response.status_code == 200:
            kernel_list_json = k_response.json()
            if len(kernel_list_json) != 0 :
                for kernel in kernel_list_json:
                    kernel_id = kernel["kernel_id"]
                    state_api_response = requests.get("{}/{}/jkg/api/kernels/{}".format(hb_endpoint, instance_id, kernel_id), headers=headers, verify=False, timeout=120)
                    if state_api_response.status_code == 200:
                        active_kernel_json = state_api_response.json()
                        active_time = active_kernel_json["last_activity"]
                        kernel_state = active_kernel_json["execution_state"]
                        if kernel_state != "busy":
                            print("kernel : {}".format(kernel_id))
                            utc_dt = datetime.strptime(active_time, "%Y-%m-%dT%H:%M:%S.%fZ")
                            actual_time = (utc_dt - datetime(1970, 1, 1)).total_seconds()
                            current_time = time.time()
                            time_diff = current_time - actual_time
                            time_diff = time_diff/60

                            print("time_diff {}, purge_time {}, current_time {}".format(time_diff,purge_time,current_time))

                            if time_diff > purge_time:
                                print("\n\tkernel activation time : {}\n\tIdle for time(s) : {}\n\tDeleting kernel".format(active_time,time_diff))
                                delete_kernel(hb_endpoint,instance_id,kernel_id,api_key)
                    else:
                        print("Failed to get {} jkg kernel state, got responseCode {}".format(kernel_id, state_api_response))
                        delete_kernel(hb_endpoint,instance_id,kernel_id,api_key)
            else:
                print("There are no kernels in 'Active' state under instance {}".format(instance_id))
        else:
            print("Failed to get kernels in state 'Active', got responseCode {}".format(response))
            exit(2)

    def purge_failed_kernels(kernel_service_url,instance_id,hb_endpoint):
        response = requests.get("""{}/{}/meta/api/kernels?state=Failed""".format(kernel_service_url, instance_id), headers=headers, verify=False, timeout=120)
        if response.status_code == 200:
            kernel_list_json = response.json()
            if len(kernel_list_json) != 0 :
                for kernel in kernel_list_json:
                    kernel_id = kernel["kernel_id"]
                    delete_kernel(hb_endpoint,instance_id,kernel_id,api_key)
            else:
                print("There are no kernels in 'Failed' state under instance {}".format(instance_id))
        else:
            print("Failed to get kernels in state 'Failed', got responseCode {}".format(response))

    #-------------------------------------------------------------------------------------------#
    # Delete Kernel
    #-------------------------------------------------------------------------------------------#
    def delete_kernel(hb_endpoint,instance_id,kernel_id, api_key):
        print("Deleting kernel {}".format(kernel_id))
        response = requests.delete("{}/{}/jkg/api/kernels/{}".format(hb_endpoint, instance_id, kernel_id), headers=headers, verify=False,timeout=40)
        if response.status_code != 204:
            print("Failed to delete kernel {} of instance {}".format(kernel_id, instance_id))

    # ---------------------------------------------  PARSE ARGS ------------------------------------------- #
    parser = argparse.ArgumentParser()
    parser.add_argument("instance_manager_url", help="Instance manager url to get instance details")
    parser.add_argument("instance_managerv3_url", help="Instance manager v3 url to get instance details")
    parser.add_argument("hb_endpoint", help="Hummingbird endpoint url to delete jobs")
    parser.add_argument("kernel_service_url", help="Job service url to get metadata of jobs")
    parser.add_argument("purge_time_file", help="purge time for FINISHED / FAILED jobs")
    args = parser.parse_args()


    # ---------------------------------------------  BUILD JSON  ------------------------------------------- #
    instance_manager_url = args.instance_manager_url
    hb_endpoint = args.hb_endpoint
    kernel_service_url = args.kernel_service_url
    instance_managerv3_url = args.instance_managerv3_url

    purge_time_file = args.purge_time_file

    print("Start HB Kernel cleanup")

    with open(purge_time_file) as json_file:
        data = json.load(json_file)
        purge_time = data["spark"]["idleTimeBeforeShutdown"]
        purge_time = purge_time
        print("setting purge time : {}mins".format(purge_time))


    headers = {'Content-Type':'application/json','Accept':'application/json'}
    v2instance_response = requests.get("{}/list".format(instance_manager_url), headers=headers, verify=False, timeout=120)

    v3instance_response = requests.get("{}".format(instance_managerv3_url), headers=headers, verify=False, timeout=120)

    if v2instance_response.status_code == 200:
        v2instances = v2instance_response.json()
    else:
        print("Failed to get v2 instances, got responseCode {}".format(response))
        exit(2)

    if v3instance_response.status_code == 200:
        v3instances = v3instance_response.json()
    else:
        print("Failed to get v3 instances, got responseCode {}".format(response))
        exit(2)

    for v2instance in v2instances:
        instance_id = v2instance["_id"]

        if "api_key" not in v2instance:
            api_key = None
        else:
            api_key = v2instance["api_key"]

        headers = {'Accept':'application/json','X-Api-Key':api_key}

        print("instance : {}".format(instance_id))
        if purge_time != -1:
            purge_active_kernels(kernel_service_url,instance_id,hb_endpoint,purge_time)

        purge_failed_kernels(kernel_service_url,instance_id,hb_endpoint)

    for v3instance in v3instances:
        instance_id = v3instance["instance_id"]

        if "api_key" not in v3instance:
            api_key = None
        else:
            api_key = v3instance["api_key"]

        headers = {'Accept':'application/json','X-Api-Key':api_key}

        print("instance : {}".format(instance_id))
        if purge_time != -1:
            purge_active_kernels(kernel_service_url,instance_id,hb_endpoint,purge_time)

        purge_failed_kernels(kernel_service_url,instance_id,hb_endpoint)
    exit(0)
  cleanup-terminating-pod.sh: |-
    #!/bin/bash
    
    kubectl_retry(){
    cmd=$1
    count=$2
    while [[ $count -gt 0 ]]
    do
        echo "count $count"
        eval $cmd
        exit_code=$?
        echo "exit_code : $exit_code"
        if [ $exit_code -eq 0 ]
        then
           return 0
        fi
        count=$(($count - 1))
        return $exit_code
    done
    }
    
    #--------------------------
    # Main
    #--------------------------
    
    pod_list=$(./tmp/kubectl get pods | egrep "(spark-history-deployment-*)|((jkg-deployment|spark-worker|spark-master).*-.*-.*-.*-.*)" | grep -i Terminating | awk '{ print $1}')
    
    if [[ $pod_list ]]
    then
        for i in {1..3}
        do
            kubectl_retry "./tmp/kubectl delete pod --grace-period=0 --force $pod_list" 3
        done
    else
        echo "There are not pods stuck in terminating state"
    fi
    exit 0
  cleanup-after-restore.py: |-
    #!/usr/bin/python
    '''
    Script to cleanup spark jobs
    '''
    
    import json, time
    from datetime import datetime
    import argparse
    import requests
    import sys
    import os
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    
    def purge_kernels(kernel_service_url,instance_id,state):
        response = requests.get("""{}/{}/meta/api/kernels?state={}""".format(kernel_service_url, instance_id, state), headers=headers, verify=False)
        if response.status_code == 200:
            kernel_list_json = response.json()
            if len(kernel_list_json) != 0 :
                for kernel in kernel_list_json:
                    kernel_id = kernel["kernel_id"]
                    print(kernel_id)
                    release_name=getReleaseName(kernel_id)
                    print(release_name)
                    delete_kernel_release(kernel_id,release_name)
            else:
                print("There are no kernels in {} state under instance {}".format(state,instance_id))
        else:
            print("Failed to get kernels in state {}, got responseCode {}".format(state,response))
    
    
    def purge_jobs(job_service_url,instance_id,state):
        j_response = requests.get("{}/{}/jobs/meta/list?state={}".format(job_service_url, instance_id,state), headers=headers, verify=False)
        if j_response.status_code == 200:
            jobs = j_response.json()
            if len(jobs) != 0 :
                for job in jobs:
                    job_id = job["job_id"]
                    print(job_id)
                    state = job["state"]
                    release_name=getReleaseName(job_id)
                    print(release_name)
                    delete_job_release(job_id,release_name)
            else:
                print("There are no jobs in {} state under instance {}".format(state,instance_id))
        else:
            print("Failed to get jobs in state {}, got responseCode {}".format(state,response))
    
    
    
    #-------------------------------------------------------------------------------------------#
    # Get release names
    #-------------------------------------------------------------------------------------------#
    def getReleaseName(unique_id):
        host=os.getenv("KUBERNETES_SERVICE_HOST")
        print(host)
        port=os.getenv("KUBERNETES_SERVICE_PORT")
        print(port)
        f = open("/var/run/secrets/kubernetes.io/serviceaccount/token", "r")
        token=f.read()
        print(token)
        result = requests.get("https://{}:{}/api/v1/namespaces/{}/pods?labelSelector=unique_id%3D{}".format(host,port,namespace,unique_id), headers={'Authorization': 'Bearer {}'.format(token)}, verify=False)
        print(result.text)
        response=json.loads(result.text)
        return response['items'][0]['metadata']['labels']['release']
    
    #-------------------------------------------------------------------------------------------#
    # Delete Kernel
    #-------------------------------------------------------------------------------------------#
    
    def delete_kernel_release(kernel_id,release_name):
        print("Deleting resource for kernel {}".format(kernel_id))
        f = open("/opt/hb/confidential_config/cpd_service_broker/cpd_service_broker.properties", "r")
        platform_token=f.read()
        response = requests.delete("http://zen-core-api-svc:3333/v2/release/{}".format(release_name), headers={'secret': '{}'.format(platform_token)}, verify=False,timeout=40)
        if response.status_code != 202:
            print("Failed to delete kernel {} of instance {}".format(kernel_id, instance_id))
    
    
    #-------------------------------------------------------------------------------------------#
    # Delete Job
    #-------------------------------------------------------------------------------------------#
    
    def delete_job_release(job_id,release_name):
        print("Deleting resource for job {}".format(job_id))
        f = open("/opt/hb/confidential_config/cpd_service_broker/cpd_service_broker.properties", "r")
        platform_token=f.read()
        print(platform_token)
        response = requests.delete("http://zen-core-api-svc:3333/v2/release/{}".format(release_name), headers={'secret': '{}'.format(platform_token)}, verify=False,timeout=40)
        if response.status_code != 202:
            print("Failed to delete Job {} of instance {}".format(job_id, instance_id))
    
    # ---------------------------------------------  PARSE ARGS ------------------------------------------- #
    parser = argparse.ArgumentParser()
    parser.add_argument("namespace", help="Current namespace")
    args = parser.parse_args()
    
    # ---------------------------------------------  BUILD JSON  ------------------------------------------- #
    instance_manager_url = "https://spark-hb-control-plane:443/instance_manager/v1/instance"
    kernel_service_url = "https://spark-hb-control-plane:443/ae/v1"
    job_service_url = "https://spark-hb-control-plane:443/job_service/v2"
    namespace=args.namespace
    
    print("Start cleanup")
    
    
    
    headers = {'Content-Type':'application/json','Accept':'application/json'}
    response = requests.get("{}/list".format(instance_manager_url), headers=headers, verify=False)
    
    if response.status_code == 200:
        instances = response.json()
    
        for instance in instances:
            instance_id = instance["_id"]
    
            if "api_key" not in instance:
                api_key = None
            else:
                api_key = instance["api_key"]
    
            headers = {'Accept':'application/json','X-Api-Key':api_key}
    
            # Delete kernels stuck in Deploying or Deleting state
            purge_kernels(kernel_service_url,instance_id,"Deploying")
            purge_kernels(kernel_service_url,instance_id,"Deleting")
            # Delete jobs stuck in Deploying or Deleting state
            purge_jobs(job_service_url,instance_id,"DEPLOYING")
            purge_jobs(job_service_url,instance_id,"DELETING")
        exit(0)
    else:
        print("Failed to get instances, got responseCode {}".format(response))
        exit(2)
